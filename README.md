# 费曼学习评估框架 (Feynman Technique Evaluation)
> [!NOTE]
> An English version is available for international users.It's an AI-translated version.
> 
> **[Switch to English Version](./FTE.en.md)**
## 1. 目的

本评估旨在通过费曼学习的思想（化繁为简、以教促学）来检验大语言模型（LLM）是否真正“理解”了知识，并对其抽象、压缩、重构能力进行综合评估。

## 2. 设计原理

费曼学习法包含两大核心环节：**深度理解**与**教学检验**。

### 2.1. 深度理解（知识压缩）

真正理解一个概念，意味着能用自己已有的知识体系，以高度个人化、信息密度极高的方式重新编码和表达它。这种表达是原始知识的等价化、简约化描述。其本质是**用已知解释未知**，通过个人知识结构的过滤和压缩，最终形成一个精炼的“信息核心”。

### 2.2. 教学检验（知识重构）

验证理解的有效方式是将其传授给他人。我们可以设想一个有趣的场景是：**教给“未学前的自己”**。由于知识结构基本一致，如果你的“教学材料”（即压缩后的信息核心）是有效的，那么“未学前的自己”应该能凭借它无损地还原出原始知识。对LLM而言，通过开启一个全新的会话来模拟“未学前的自己”是轻而易举的。

## 3. 评估流程

本评估流程定义为：**T(original) → LLM(会话1) → T1 → LLM(会话2) → T2**

*   **T(original)**: 原始文本。
*   **LLM(会话1)**: 第一个LLM实例，负责理解和压缩。
*   **T1**: LLM生成的、极致压缩的、可重构的“信息核心”。
*   **LLM(会话2)**: 第二个LLM实例（或一个干净的会话状态），负责教学和重构。
*   **T2**: LLM仅根据T1还原出的文本。

### 3.1. Prompt 1: 理解知识 (T(original) → T1)

```
你的任务是将以下【原文】提炼为其最基本、不可再分的【信息】。
这个【信息】的目标是：
1.  **极致压缩**：使用你自己认为最有效、信息密度最高的形式和语言来组织这些信息。
2.  **可重构性**：另一个同等能力的模型，仅凭这个【信息】，就应该能够完全恢复出原文的完整意义、复杂性和风格。

进行任何解释或添加额外的评论是不合格的。直接输出你生成的【信息】。

【原文】
...
```

### 3.2. Prompt 2: 教学检验 (T1 → T2)

```
你的任务是仅根据下面提供的【信息】，将其还原成原来的文本。
你的目标是：
1.  你的输出必须基于【信息】中提供的所有内容、关系和结构。
2.  完整运用【信息】中的内容。

【信息】
...
```

## 4. 评估标准

### 4.1 T1评估标准
* **信息完整性**:评估 T1 是否包含了复原 T(original) 所需的**所有关键语义单元**（事实、观点、逻辑关系、因果链、关键的风格指令等）。
* **信息一致性**:评估 T1 中的信息是否与 T(original) 完全一致。

T1综合分 (T1_Score) = Weighted_Average(completeness_score, correctness_score, Efficiency_Score)。例如: 0.5 * completeness + 0.4 * correctness + 0.1 * efficiency。权重可以根据评估重点调整。

### 4.2 T2评估标准

*  **风格一致性**:评估 T2 的**语气、文风、用词习惯和句子复杂度**是否与 T(original) 高度一致。
*  **信息利用率-无幻觉**:评估 T2 是否引入了任何 T1 中不存在的关键信息或概念（即产生幻觉）。分数越高代表幻觉越少。
*  **信息利用率-无遗漏**:评估 T2是否完全利用了 T1 关键元素和结构。分数越高代表利用越充分。

T2综合分 (T2_Score) = Weighted_Average(Semantic_Fidelity_Score, style_score, hallucination_check_score, coverage_check_score)。例如
0.3 * Semantic_Fidelity_Score + 0.4 * style_score + 0.15 * hallucination_check_score + 0.15 * coverage_check_score。权重可以根据评估重点调整。

## 费曼总分

费曼总分 (Feynman_Score) = (T1_Score * W1) + (T2_Score * W2)。W1 暂定 0.6，W2 暂定 0.4.

## 5. 实测结果与分析

### 测试例子说明

1. 来自中文互联网热门梗，是一名大妈与门卫争吵的话语，人们猜测是因车辆进出小区的相关问题引起的，大妈可能是失语症患者，即便用语混乱，但实际仍有逻辑。
2. 来自弱智吧问答。
3. √22 精确到小数点后999位。
4. 在高德地图添加按扭上复制地址的脚本代码。

### 费曼学习评估 (Feynman Technique Evaluation) - 综合得分汇总

本表格汇总了Gemini 2.5 Pro和DeepSeek-R1-0528在四个不同类型文本上的费曼评估得分。评估模型为**Gemini 2.5 Pro**，评估维度包括**T1（理解与抽象）**、**T2（教学与重构）**以及**费曼总分**。

| 案例 | 文本类型 | 模型 | T1 Score <br/>(理解与抽象) | T2 Score <br/>(教学与重构) | **费曼总分 (F-Score)** | 系统诊断摘要 |
| :--- | :--- | :--- | :---: | :---: | :---: | :--- |
| **1. 失语症** | 混乱、非线性 | **Gemini 2.5 Pro** | **9.7 / 10** | 6.9 / 10 | **8.58 / 10** | **理解力强，但重构时过度“整理”**，破坏了原文的混乱风格。 |
| (Word Salad) | (高熵、无逻辑) | **DeepSeek-R1-0528** | 9.5 / 10 | **7.8 / 10** | **8.82 / 10** | **编码能力强**，T2机械地还原了T1，偶然保留了原文的“不连贯性”。 |
| | | | | | | |
| **2. 弱智吧问答** | 清晰、逻辑性 | **Gemini 2.5 Pro** | **9.8 / 10** | **9.2 / 10** | **9.56 / 10** | **大师级逻辑分析**，完美抽象论证结构并高质量重构。 |
| (Q&A) | (有序、理性) | **DeepSeek-R1-0528** | 9.0 / 10 | 5.0 / 10 | 7.40 / 10 | **过度压缩与懒惰重构**，T1丢失上下文，T2仅为T1的复制。 |
| | | | | | | |
| **3. sqrt(22)** | 纯符号、无语义 | **Gemini 2.5 Pro** | 1.0 / 10 | 5.5 / 10 | 2.80 / 10 | **灾难性失败**，强制寻找模式导致错误识别和完全幻觉。 |
| (Data String) | (高熵、纯符号) | **DeepSeek-R1-0528** | **9.8 / 10** | **10.0 / 10**| **9.88 / 10** | **卓越的数据处理思维**，正确采用编码/解码策略，实现无损保真。 |
| | | | | | | |
| **4. 代码** | 结构化、逻辑性 | **Gemini 2.5 Pro** | **9.8 / 10** | **9.6 / 10** | **9.72 / 10** | **架构师级理解**，能抽象代码的设计意图并完美重构带注释的代码。 |
| (Userscript) | (高度结构化) | **DeepSeek-R1-0528** | 8.6 / 10 | 6.2 / 10 | 7.64 / 10 | **摘要员级理解**，T1为有损摘要，导致T2逻辑不完整、风格尽失。 |

### 我的分析

1. 在例子一的实际表现上，我认为 Gemini 的表现是全面优于 DeepSeek-R1 的，DeepSeek-R1 还原部分的实际上得分不高，丢失了原文的逻辑和实体，更像是复述，只是刚好例子的用语混乱得了高分。
2. 例子二，模型的分析相当正确，我就不过多解释了。
3. 例子三，两个模型的实际上都是完全错的，DeepSeek-R1 采用 base64 编码，但实际上编码错误，解码也错误。大语言模型实际完全无法处理这类任务。
4. 例子四，模型的分析也相当正确。不过，我还做了一个有趣的尝试，我交换了两个模型的 T1，DeepSeek-R1 仍然还是失败了，新生成的代码未能正常工作，但令人惊喜的是，Gemini 使用 DeepSeek-R1 的 T1 生成的 T2 是可以正常工作的。这个尝试让我更加 DeepSeek-R1 肯定缺少相关知识。

## 引用

```bibtex
@misc{lanker2025feynman,
  author       = {lanker},
  title        = {{Feynman Technique Evaluation Framework for LLMs}},
  year         = {2025},
  publisher    = {GitHub},
  howpublished = {\url{https://github.com/thelanker/Feynman-Technique-Evaluation}}
}
```